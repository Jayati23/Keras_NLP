{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "simple_universal_sentence_encoder.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Jayati23/Keras_NLP/blob/master/simple_universal_sentence_encoder.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2QNscFw8_0Kn",
        "colab_type": "code",
        "outputId": "97688e3d-5db7-43a5-a172-181cb5c7c8d6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "\n",
        "import  numpy  as  np\n",
        "import  tensorflow  as tf\n",
        "import tensorflow_hub as hub\n",
        "import csv\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from google.colab import drive\n",
        "import re\n",
        "drive.mount('/content/gdrive')\n",
        "import nltk\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8b4Re3C2_7VT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open(\"/content/gdrive/My Drive/Colab Notebooks/quora.tsv\") as tsvfile:\n",
        "    tsvreader = csv.reader(tsvfile, delimiter=\"\\t\")\n",
        "   \n",
        "    quest1 = []\n",
        "    quest2 = []\n",
        "    dup = []\n",
        "    for line in tsvreader:\n",
        "        quest1.append(line[3])\n",
        "        quest2.append(line[4])\n",
        "        dup.append(line[5])\n",
        "        \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3i_jt-aKOaeA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "module_url = \"https://tfhub.dev/google/universal-sentence-encoder/1\"\n",
        "embed = hub.Module(module_url)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A1mcx_G0BsBb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def remove_stopwords(stop_words, tokens):\n",
        "    res = []\n",
        "    for token in tokens:\n",
        "        if not token in stop_words:\n",
        "            res.append(token)\n",
        " \n",
        "    return res\n",
        "\n",
        "def process_text(text):\n",
        " #   text = text.encode('ascii', errors='ignore').decode()\n",
        "    text = text.lower()\n",
        "    text = re.sub(r'http\\S+', ' ', text)\n",
        "    text = re.sub(r'#+', ' ', text )\n",
        "    text = re.sub(r'@[A-Za-z0-9]+', ' ', text)\n",
        "    text = re.sub(r\"([A-Za-z]+)'s\", r\"\\1 is\", text)\n",
        "    #text = re.sub(r\"\\'s\", \" \", text)\n",
        "    text = re.sub(r\"\\'ve\", \" have \", text)\n",
        "    text = re.sub(r\"won't\", \"will not \", text)\n",
        "    text = re.sub(r\"isn't\", \"is not \", text)\n",
        "    text = re.sub(r\"can't\", \"can not \", text)\n",
        "    text = re.sub(r\"n't\", \" not \", text)\n",
        "    text = re.sub(r\"i'm\", \"i am \", text)\n",
        "    text = re.sub(r\"\\'re\", \" are \", text)\n",
        "    text = re.sub(r\"\\'d\", \" would \", text)\n",
        "    text = re.sub(r\"\\'ll\", \" will \", text)\n",
        "    text = re.sub('\\W', ' ', text)\n",
        "    text = re.sub(r'\\d+', ' ', text)\n",
        "    text = re.sub('\\s+', ' ', text)\n",
        "    text = text.strip()\n",
        "    return text\n",
        "\n",
        "def lemmatize(tokens):\n",
        "    lemmatizer = nltk.stem.WordNetLemmatizer()\n",
        "    lemma_list = []\n",
        "    for token in tokens:\n",
        "        lemma = lemmatizer.lemmatize(token, 'v')\n",
        "        if lemma == token:\n",
        "            lemma = lemmatizer.lemmatize(token)\n",
        "        lemma_list.append(lemma)\n",
        "    # return [ lemmatizer.lemmatize(token, 'v') for token in tokens ]\n",
        "    return lemma_list\n",
        "\n",
        "\n",
        "def process_all(text):\n",
        "    text = process_text(text)\n",
        "    stop_words = ['.',',','!', 'ourselves', 'hers','between','yourself', 'but', 'again', 'there', 'about', 'once','during', 'out', 'very', 'having', 'with', 'they', 'own', 'an', 'be', 'some', 'for', 'do', 'its', 'yours', 'such', 'into', 'of', 'most', 'itself','other', 'off', 'is', 's', 'am', 'or', 'who', 'as', 'from', 'him', 'each', 'the', 'themselves', 'until', 'below', 'are', 'we', 'these', 'your', 'his', 'through', 'don', 'nor', 'me', 'were', 'her', 'more', 'himself', 'this', 'down', 'should', 'our', 'their', 'while', 'above', 'both', 'up', 'to', 'ours', 'had', 'she', 'all', 'no', 'when', 'at', 'any', 'before', 'them', 'same', 'and', 'been', 'have', 'in', 'will', 'on', 'does', 'yourselves', 'then', 'that', 'because', 'what', 'over', 'why', 'so', 'can', 'did', 'not', 'now', 'under', 'he', 'you', 'herself', 'has', 'just', 'where', 'too', 'only', 'myself', 'which', 'those', 'i','after', 'few', 'whom', 't', 'being', 'if', 'theirs', 'my', 'against', 'a', 'by', 'doing', 'it', 'how', 'further', 'was', 'here', 'than']\n",
        "    return ' '.join(remove_stopwords(stop_words, text.split()))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8qemdBtmNYOd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def cosine_similarity(v1, v2):\n",
        "    mag1 = np.linalg.norm(v1)\n",
        "    mag2 = np.linalg.norm(v2)\n",
        "    if (not mag1) or (not mag2):\n",
        "        return 0\n",
        "    return np.dot(v1, v2) / (mag1 * mag2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b5FBmkpuOOnp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_features(texts):\n",
        "    if type(texts) is str:\n",
        "        texts = [texts]\n",
        "    with tf.Session() as sess:\n",
        "        sess.run([tf.global_variables_initializer(), tf.tables_initializer()])\n",
        "        return sess.run(embed(texts))\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_mzE4dmVNiM8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def test_similarity(text1, text2):\n",
        "    vec1 = get_features(text1)[0]\n",
        "    vec2 = get_features(text2)[0]\n",
        "    return cosine_similarity(vec1, vec2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "im_DONRsFyDi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "quest1_final = [] \n",
        "quest2_final = [] \n",
        "\n",
        "for i in range(len(quest1)):\n",
        "  quest1_final.append(process_text(quest1[i]))\n",
        "  quest2_final.append(process_text(quest2[i]))\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J4pFtwZ4O8e9",
        "colab_type": "code",
        "outputId": "ae2e8c8a-c4eb-49af-94d5-e85f7f6ccd1e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        }
      },
      "source": [
        "count = 0\n",
        "for i in range(1,10):\n",
        "  sent1 = quest1_final[i]\n",
        "  sent2 = quest2_final[i]\n",
        "  print(sent1, sent2)\n",
        "  k = test_similarity(sent1,sent2)\n",
        "  print(k, dup[i])\n",
        "  if(k >= 0.85 and dup[i] == '1'):\n",
        "    count = count +1\n",
        "  elif(k < 0.85 and dup[i] == '0'):\n",
        "    count = count + 1\n",
        "    \n",
        "    \n",
        "print(count)\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "what is the step by step guide to invest in share market in india what is the step by step guide to invest in share market\n",
            "0.9638024 0\n",
            "what is the story of kohinoor koh i noor diamond what would happen if the indian government stole the kohinoor koh i noor diamond back\n",
            "0.63465446 0\n",
            "how can i increase the speed of my internet connection while using a vpn how can internet speed be increased by hacking through dns\n",
            "0.89566684 0\n",
            "why am i mentally very lonely how can i solve it find the remainder when math math is divided by\n",
            "0.31800973 0\n",
            "which one dissolve in water quikly sugar salt methane and carbon di oxide which fish would survive in salt water\n",
            "0.52574474 0\n",
            "astrology i am a capricorn sun cap moon and cap rising what does that say about me i am a triple capricorn sun moon and ascendant in capricorn what does this say about me\n",
            "0.9356637 1\n",
            "should i buy tiago what keeps childern active and far from phone and video games\n",
            "0.019359237 0\n",
            "how can i be a good geologist what should i do to be a great geologist\n",
            "0.95286214 1\n",
            "when do you use シ instead of し when do you use instead of and\n",
            "0.7897374 0\n",
            "7\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2zdnk0TdT2Id",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}